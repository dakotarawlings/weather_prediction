{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Builds a model for predicting the air temperature based on our cleaned and engineered NDBC data in our DB\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.deterministic import CalendarFourier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format a dataframe after impoting from SQL\n",
    "def format_df(df_in):\n",
    "    \"\"\"Function for formatting a dataframe from the database file with model training NDBC data\n",
    "\n",
    "    Args:\n",
    "            df_in (dataframe): Dataframe that has been uploaded from NDBC SQL database\n",
    "\n",
    "    Returns:\n",
    "            dataframe: formatted dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df=df_in.copy(deep=True)\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    df=df.set_index('datetime')\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NDBC_historical_raw_data',), ('NDBC_historical_raw_data_St#{STATIONNUMBER}',), ('NDBC_historical_raw_data_St{STATIONNUMBER}',), ('NDBC_historical_raw_data_St46054',), ('NDBC_historical_cleaned_data',), ('NDBC_historical_data_for_training',)]\n"
     ]
    }
   ],
   "source": [
    "#Query a list of tables from our SQL model building DB\n",
    "con = sqlite3.connect(r\"C:\\Users\\dakot\\Desktop\\DataScience\\projects\\weather_prediction\\NDBC_model_building_database.db\")\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query engineered data from DB\n",
    "conn = sqlite3.connect(r\"C:\\Users\\dakot\\Desktop\\DataScience\\projects\\weather_prediction\\NDBC_model_building_database.db\")\n",
    "df_training = pd.read_sql_query(\"SELECT * FROM NDBC_historical_data_for_training\", conn, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use our function defined above to format our data\n",
    "df_training=format_df(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our custom BoostedHybrid model class from a seperate file\n",
    "#note: saving our custom mode class as a seperate file makes it easier to pickle and unpickle the model for productionalization\n",
    "from BoostedHybridModel import BoostedHybridModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WDIR', 'WSPD', 'GST', 'PRES', 'ATMP', 'WTMP', 'date', 'const', 'trend',\n",
       "       'sin(1,freq=A-DEC)', 'cos(1,freq=A-DEC)', 'sin(2,freq=A-DEC)',\n",
       "       'cos(2,freq=A-DEC)', 'sin(3,freq=A-DEC)', 'cos(3,freq=A-DEC)',\n",
       "       'ATMP_lag_1', 'ATMP_lag_2', 'ATMP_lag_3', 'ATMP_lag_4', 'ATMP_lag_5',\n",
       "       'ATMP_lag_6', 'ATMP_lag_7', 'ATMP_lag_8', 'WTMP_lag_1', 'WTMP_lag_2',\n",
       "       'WTMP_lag_3', 'WTMP_lag_4', 'WTMP_lag_5', 'WTMP_lag_6', 'WTMP_lag_7',\n",
       "       'WTMP_lag_8', 'WSPD_lag_1', 'WSPD_lag_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Our boosted hybrid model has two models: here we use a linear model that is just our fourier fit and a XGB model that predicts the residals\n",
    "#The features for our first model are just fourier features which are generated automatically by our class\n",
    "\n",
    "#For the XGB part of our model we use all of our lag features to predict the target value in 1 day (one timestep)\n",
    "X_model_2=df_training[['ATMP_lag_1', 'ATMP_lag_2', 'ATMP_lag_3',\n",
    "       'ATMP_lag_4', 'ATMP_lag_5', 'ATMP_lag_6', 'ATMP_lag_7', 'ATMP_lag_8',\n",
    "       'WTMP_lag_1', 'WTMP_lag_2', 'WTMP_lag_3', 'WTMP_lag_4', 'WTMP_lag_5',\n",
    "       'WTMP_lag_6', 'WTMP_lag_7', 'WTMP_lag_8', 'WSPD_lag_1', 'WSPD_lag_2']]\n",
    "#Here we are using air temp as our target \n",
    "y=df_training['ATMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use train test split to split our target and features into test and training sets\n",
    "X_model_2_train, X_model_2_test, y_train, y_test = train_test_split( X_model_2, y, test_size=.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set our first and second models of our boosted hybrid model and fit to our training data\n",
    "model_1=LinearRegression()\n",
    "model_2=XGBRegressor()\n",
    "model=BoostedHybridModel(model_1, model_2)\n",
    "model.fit(X_model_2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Apply our model to testing data\n",
    "y_pred = model.predict(X_model_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9662063072859188"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate MAE for our predicted data\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle our model for use in productionalization\n",
    "import pickle\n",
    "modelFile = open('TemperatureModel_OneDay.p', 'wb')\n",
    "pickle.dump(model, modelFile)                     \n",
    "modelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9662063072859188"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing our pickled model to make sure everything works well before productionalization\n",
    "modelFile = open('TemperatureModel_OneDay.p', 'rb')     \n",
    "pmodel = pickle.load(modelFile)\n",
    "y_predp=pmodel.predict(X_model_2_test)\n",
    "modelFile.close()\n",
    "mean_absolute_error( y_test, y_predp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now make a second model to predict the value of ou target in two time steps\n",
    "X_model_2=df_training[[ 'ATMP_lag_2', 'ATMP_lag_3',\n",
    "       'ATMP_lag_4', 'ATMP_lag_5', 'ATMP_lag_6', 'ATMP_lag_7', 'ATMP_lag_8',\n",
    "        'WTMP_lag_2', 'WTMP_lag_3', 'WTMP_lag_4', 'WTMP_lag_5',\n",
    "       'WTMP_lag_6', 'WTMP_lag_7', 'WTMP_lag_8', 'WSPD_lag_2']]\n",
    "\n",
    "y=df_training['ATMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new training and testing data since this model is indempendent from our 1 day model\n",
    "X_model_2_train, X_model_2_test, y_train, y_test = train_test_split( X_model_2, y, test_size=.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Follow same procedure to build 2-day model with our new train/test data\n",
    "model_1=LinearRegression()\n",
    "model_2=XGBRegressor()\n",
    "model=BoostedHybridModel(model_1, model_2)\n",
    "model.fit(X_model_2_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_model_2_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error( y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serialize our two day model \n",
    "import pickle\n",
    "modelFile = open('TemperatureModel_TwoDay.p', 'wb')\n",
    "pickle.dump(model, modelFile)                     \n",
    "modelFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2087390774034952"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test our serialized model before deployment\n",
    "modelFile = open('TemperatureModel_TwoDay.p', 'rb')     \n",
    "pmodel = pickle.load(modelFile)\n",
    "y_predp=pmodel.predict(X_model_2_test)\n",
    "modelFile.close()\n",
    "mean_absolute_error( y_test, y_predp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b70063081feeb4abd36a4e5ee8777e95d61b757eeead7e6f964b4a5552d00fee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
